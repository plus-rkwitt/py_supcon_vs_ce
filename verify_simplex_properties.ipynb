{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import core.experiment\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from pytorch_utils.logging import LoggerReader\n",
    "from pytorch_utils.evaluation import apply_model, argmax_and_accuracy\n",
    "from nb_common import load_experiment_context, load_results, compute_latent, args_df_from_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy_loss(path, run_i=0, train=True, device=DEVICE):\n",
    "    exp_context = load_experiment_context(path, run_i=run_i)\n",
    "    \n",
    "    if train:\n",
    "        ds = exp_context['ds_train']\n",
    "    else:\n",
    "        ds = exp_context['ds_test']\n",
    "        \n",
    "    Y_hat, Y = apply_model(dataset=ds, model=exp_context['model'], device=device, shuffle=False)\n",
    "    \n",
    "    return torch.nn.functional.cross_entropy(\n",
    "        torch.tensor(Y_hat), \n",
    "        torch.tensor(Y)\n",
    "        , reduction='mean').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent_innerproducts_norm(path, run_i=0, train=True, sub_sample=None, device=DEVICE):\n",
    "    Z, Y = compute_latent(path, run_i, train, device=device)\n",
    "    \n",
    "    if sub_sample is not None:\n",
    "        assert isinstance(sub_sample, int)\n",
    "        I = torch.randperm(len(Z))\n",
    "        I = I[:sub_sample]\n",
    "        Z = [Z[i] for i in I]\n",
    "        Y = [Y[i] for i in I]\n",
    "    \n",
    "    labels = set(Y)\n",
    "    assert labels == set(range(len(labels)))\n",
    "    \n",
    "    bs = 512\n",
    "    \n",
    "    ds_1 = torch.utils.data.dataset.TensorDataset(torch.tensor(Z), torch.tensor(Y))    \n",
    "    dl_1 = torch.utils.data.DataLoader(ds_1, shuffle=False, batch_size=bs)\n",
    "    \n",
    "    list_D = []\n",
    "    list_Y = []\n",
    "    list_N = []\n",
    "    \n",
    "    for batch_i, (x_1, y_1) in enumerate(dl_1):\n",
    "        \n",
    "        Z_, Y_ = ds_1.tensors\n",
    "        Z_, Y_ = Z_[bs*batch_i:], Y_[bs*batch_i:]\n",
    "        ds_2 = torch.utils.data.dataset.TensorDataset(Z_, Y_)\n",
    "        dl_2 = torch.utils.data.DataLoader(ds_2, shuffle=False, batch_size=bs)\n",
    "        \n",
    "        for batch_j, (x_2, y_2) in enumerate(dl_2):    \n",
    "                        \n",
    "            D = (x_1.unsqueeze(0)*x_2.unsqueeze(1)).sum(dim=-1)\n",
    "            \n",
    "            x_1_norm = torch.norm(x_1, p=2, dim=1)\n",
    "            x_2_norm = torch.norm(x_2, p=2, dim=1)\n",
    "            \n",
    "            N = torch.cat([\n",
    "                x_2_norm.view(-1, 1, 1).expand(-1, x_1_norm.size(0), -1),\n",
    "                x_1_norm.view(1, -1, 1).expand(x_2_norm.size(0),-1, -1)\n",
    "            ], dim=2)\n",
    "            \n",
    "            Y = torch.cat([\n",
    "                y_2.view(-1, 1, 1).expand(-1, x_1.size(0), -1),\n",
    "                y_1.view(1, -1, 1).expand(x_2.size(0),-1, -1)\n",
    "            ], dim=2) \n",
    "            \n",
    "            # Test that this is really implemented the right way\n",
    "            #             y_1 = torch.tensor([0, 1, 2])\n",
    "            #             y_2 = torch.tensor([3, 4, 5, 6])\n",
    "            #             x_1 = torch.randn(3, 10)\n",
    "            #             x_2 = torch.randn(4, 10)\n",
    "\n",
    "            #             D = (x_1.unsqueeze(0)*x_2.unsqueeze(1)).sum(dim=-1)\n",
    "\n",
    "            #             Y = torch.cat([\n",
    "            #                 y_2.view(-1, 1, 1).expand(-1, x_1.size(0), -1),\n",
    "            #                 y_1.view(1, -1, 1).expand(x_2.size(0),-1, -1)\n",
    "            #             ], dim=2)\n",
    "\n",
    "            #             for i, j in Y.view(-1, 2):\n",
    "            #                 i = i -3\n",
    "\n",
    "            #                 assert D[i, j].item() == (x_2[i]*x_1[j]).sum().item()\n",
    "            \n",
    "            # Sort labels ascendingly \n",
    "            Y, I = Y.sort(dim=-1)\n",
    "            \n",
    "            # Apply sorting permutation to norms \n",
    "            N = N.gather(2, I)\n",
    "            \n",
    "            # The first batch in the batch_j loop is always the batch_i-th batch. \n",
    "            # We take the upperdiagonal part of this innerproduct matrix. \n",
    "            if batch_j == 0:\n",
    "                mask = torch.ones_like(D, dtype=torch.bool).triu(diagonal=1)\n",
    "                \n",
    "                D = D[mask]\n",
    "                Y = Y[mask]      \n",
    "                N = N[mask]\n",
    "            \n",
    "            \n",
    "            list_D.append(D.view(-1))\n",
    "            list_Y.append(Y.view(-1, 2))\n",
    "            list_N.append(N.view(-1, 2))\n",
    "            \n",
    "                \n",
    "    D, Y, N = torch.cat(list_D, dim=0), torch.cat(list_Y, dim=0), torch.cat(list_N, dim=0)\n",
    "    \n",
    "    assert D.size(0) == len(Z)*(len(Z)-1) / 2\n",
    "    assert D.size(0) == Y.size(0)\n",
    "    assert Y.size() == N.size()\n",
    "\n",
    "    return D, Y, N\n",
    "\n",
    "\n",
    "def compute_latent_norms(path, run_i=0, train=True, device=DEVICE):\n",
    "    Z, Y = compute_latent(path, run_i, train, device=device)\n",
    "    \n",
    "    return torch.tensor(Z).norm(p=2, dim=-1), Y\n",
    "\n",
    "\n",
    "def compute_linear_weights_norm(path, run_i=0):\n",
    "    exp_context = load_experiment_context(path, run_i=run_i)\n",
    "    return exp_context['model'].cls.weight.norm(p=2, dim=-1).detach()\n",
    "\n",
    "\n",
    "def compute_latent_innerprod_with_weight(path, run_i=0, train=True, device=DEVICE):\n",
    "    exp_context = load_experiment_context(path, run_i=run_i)\n",
    "   \n",
    "    if exp_context['args']['model'][1]['linear_cfg'][1]['bias']:\n",
    "        print('warning')\n",
    "    \n",
    "    if train:\n",
    "        ds = exp_context['ds_train']\n",
    "    else:\n",
    "        ds = exp_context['ds_test']\n",
    "        \n",
    "    Y_hat, Y = apply_model(dataset=ds, model=exp_context['model'], device=device)\n",
    "    \n",
    "    return torch.tensor(Y_hat), Y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_context = load_experiment_context(named_results['CEF'].path, run_i=0)\n",
    "# W = exp_context['model'].cls.weight.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_comp</th>\n",
       "      <th>model_lin</th>\n",
       "      <th>loss</th>\n",
       "      <th>scheduler</th>\n",
       "      <th>ds_train</th>\n",
       "      <th>augment</th>\n",
       "      <th>progress</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>Linear</td>\n",
       "      <td>CrossEntropy</td>\n",
       "      <td>exponential</td>\n",
       "      <td>cifar100_train</td>\n",
       "      <td>standard</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sphere_l2</td>\n",
       "      <td>Linear</td>\n",
       "      <td>SupConLoss</td>\n",
       "      <td>exponential</td>\n",
       "      <td>cifar100_train</td>\n",
       "      <td>standard</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>FixedSphericalSimplexLinear</td>\n",
       "      <td>CrossEntropy</td>\n",
       "      <td>exponential</td>\n",
       "      <td>cifar10_train</td>\n",
       "      <td>none</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_comp                    model_lin          loss    scheduler  \\\n",
       "0       none                       Linear  CrossEntropy  exponential   \n",
       "1  sphere_l2                       Linear    SupConLoss  exponential   \n",
       "2       none  FixedSphericalSimplexLinear  CrossEntropy  exponential   \n",
       "\n",
       "         ds_train   augment  progress  \n",
       "0  cifar100_train  standard      True  \n",
       "1  cifar100_train  standard      True  \n",
       "2   cifar10_train      none      True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = Path('/home/pma/chofer/repositories/py_supcon_vs_ce/results_xmas_performance/')\n",
    "named_results = {\n",
    "#     'CEV':   9, \n",
    "#     'SUP':   2, \n",
    "#     'CEF':  49 \n",
    "    'CEV':   13, \n",
    "    'SUP':   5, \n",
    "    'CEF':  48 #->  \n",
    "\n",
    "    \n",
    "#     'CEV':   8, \n",
    "#     'SUP':   0, \n",
    "#     'CEF':  48\n",
    "    # CIFAR100\n",
    "    #'SUP': 4,\n",
    "    #'CEF': 56,\n",
    "    #'CEV': 12\n",
    "    \n",
    "}\n",
    "\n",
    "args_simple = {\n",
    "    'model_comp': lambda a: a['model'][1]['compactification_cfg'][0], \n",
    "    'model_lin': lambda a: a['model'][1]['linear_cfg'][0], \n",
    "    'loss': lambda a: a['losses'][0][0],\n",
    "    'scheduler': lambda a: a['scheduler'],\n",
    "    'ds_train': lambda a: a['ds_train'],\n",
    "    'augment': lambda a: a['augment']\n",
    "}\n",
    "\n",
    "latent_geometry = {}\n",
    "results = load_results(root)\n",
    "named_results = {k: results[v] for k, v in named_results.items()}\n",
    "args_df_from_results(named_results.values(), args_simple=args_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angular_distance(data):\n",
    "    #return cosine_similarity(data)\n",
    "\n",
    "    return 1-np.arccos(np.clip(cosine_similarity(data),-1.0,1.0))/np.pi    \n",
    "\n",
    "def compute_wei_cross_angular_distances(result):\n",
    "    exp_context = load_experiment_context(result.path, run_i=0)\n",
    "\n",
    "    # extract classifier weight\n",
    "    W = exp_context['model'].cls.weight.detach().numpy()\n",
    "\n",
    "    # compute angular distance and get cross-class parts\n",
    "    nrows, ncols = W.shape\n",
    "    CW = compute_angular_distance(W)\n",
    "    CW_lower_triu = CW[np.triu_indices(nrows, k=1)]\n",
    "    return CW_lower_triu\n",
    "\n",
    "def compute_cls_cross_angular_distances(result, latent_dim=512):\n",
    "    \n",
    "    # get latent codes\n",
    "    Z, Y = compute_latent(result.path, 0, True, device='cuda:2')\n",
    "    ZM = torch.tensor(Z)\n",
    "    YM = torch.tensor(Y)\n",
    "    \n",
    "    nlabels = len(np.unique(YM))\n",
    "\n",
    "    # compute class means\n",
    "    means = np.zeros((nlabels, latent_dim))\n",
    "    for i in range(nlabels):\n",
    "        means[i,:] = ZM[YM==i].mean(dim=0).numpy()\n",
    "\n",
    "    # compute angular distance across means and extract cross-class parts\n",
    "    nrows, ncols = means.shape\n",
    "    D = compute_angular_distance(means)\n",
    "    D_lt = D[np.triu_indices(nrows,k=1)]\n",
    "    return D_lt \n",
    "\n",
    "def compute_class_mean_ips(result, latent_dim=512):\n",
    "    Z, Y = compute_latent(result.path, 0, True, device='cuda:2')\n",
    "    ZM = torch.tensor(Z)\n",
    "    YM = torch.tensor(Y)\n",
    "    \n",
    "    nlabels = len(np.unique(YM))\n",
    "\n",
    "    ips = []\n",
    "    for i in range(nlabels):\n",
    "        a = ZM[YM==i].numpy()\n",
    "        b = ZM[YM==i].mean(dim=0).numpy().reshape(1,latent_dim)\n",
    "        ip = 1-np.arccos(np.clip(cosine_similarity(a,b),-1.0,1.0))/np.pi \n",
    "        ips.append(ip.reshape(-1))\n",
    "    \n",
    "    ips_np = np.concatenate(ips)\n",
    "    return ips_np\n",
    "\n",
    "def compute_class_collapse(result, latent_dim=512):\n",
    "    Z, Y = compute_latent(result.path, 0, True, device='cuda:2')\n",
    "    ZM = torch.tensor(Z)\n",
    "    YM = torch.tensor(Y)\n",
    "    \n",
    "    nlabels = len(np.unique(YM))\n",
    "\n",
    "    collapse = []\n",
    "    for i in range(nlabels):\n",
    "        collapse.append((ZM[YM==i] - ZM[YM==i].mean(axis=0)).norm(dim=1,p=2).numpy())\n",
    "    return collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_cev_CAD = compute_cls_cross_angular_distances(named_results['CEV'])\n",
    "P_sup_CAD = compute_cls_cross_angular_distances(named_results['SUP'])\n",
    "P_cef_CAD = compute_cls_cross_angular_distances(named_results['CEF'])\n",
    "\n",
    "P_sup_CMIPS = compute_class_mean_ips(named_results['SUP'], latent_dim=512)\n",
    "P_cev_CMIPS = compute_class_mean_ips(named_results['CEV'], latent_dim=512)\n",
    "P_cef_CMIPS = compute_class_mean_ips(named_results['CEF'], latent_dim=512)\n",
    "\n",
    "W_cef_CAD = compute_wei_cross_angular_distances(named_results['CEF'])\n",
    "W_cev_CAD = compute_wei_cross_angular_distances(named_results['CEV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 756x108 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "def geom_properties(cad, cc, weights, outfile=None, K=10):\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": [\"Times\"],\n",
    "    })\n",
    "    \n",
    "    fig, (ax1, ax3, ax2) = plt.subplots(1,3,figsize=(10.5,1.5))\n",
    "    \n",
    "    sns.boxplot(data=weights, orient='h', ax=ax3,showfliers=False)\n",
    "    ax3.set_yticklabels([r'\\textbf{CE}',r'\\textbf{CE} (Fix)',r'\\textbf{SC}'], fontsize=12)\n",
    "    ax3.axvline(x=1-np.arccos(-1.0/(K-1))/np.pi, ymin=0, ymax=2, color='tab:red',linewidth=2)\n",
    "    ax3.set_title(r'Cosine similarity \\textbf{across} weights')\n",
    "    ax3.set_yticklabels([])\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax3.tick_params(axis='both', which='minor', labelsize=12)\n",
    "    ax3.set_xlim(0.39,0.6)\n",
    "\n",
    "    \n",
    "    sns.boxplot(data=cad, orient='h', ax=ax1,showfliers=False)\n",
    "    ax1.set_yticklabels([r'\\textbf{CE}',r'\\textbf{CE-fix}',r'\\textbf{SC}'], fontsize=12)\n",
    "    ax1.axvline(x=1-np.arccos(-1.0/(K-1))/np.pi, ymin=0, ymax=2, color='tab:red',linewidth=2)\n",
    "    ax1.set_title(r'Cosine similarity \\textbf{across} class means')\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax1.tick_params(axis='both', which='minor', labelsize=12)\n",
    "    ax1.set_xlim(0.45,0.7)\n",
    "    \n",
    "    sns.boxplot(data=cc, orient='h', ax=ax2,showfliers=False)\n",
    "    ax2.axvline(x=1.0, ymin=0, ymax=2, color='tab:red',linewidth=2)\n",
    "    #ax2.text(1.0035, 1.3, 'Optimal', rotation=90, color='tab:red', fontsize=12)\n",
    "    ax2.set_xlim(0.75,1.01)\n",
    "    ax2.set_yticklabels([])\n",
    "    ax2.set_title(r'Cosine similarity \\textbf{to} class means', fontsize=12)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax2.tick_params(axis='both', which='minor', labelsize=12)\n",
    "\n",
    "    if outfile is not None:\n",
    "        plt.savefig(outfile, bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "\n",
    "geom_properties(cad=[P_cev_CAD, P_cef_CAD, P_sup_CAD], \n",
    "                cc=[P_cev_CMIPS, P_cef_CMIPS, P_sup_CMIPS], \n",
    "                weights=[W_cev_CAD, W_cef_CAD, P_sup_CAD], outfile='/tmp/real_data_simplex_eval/geometry_cifar100.pdf',\n",
    "                K=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "# matplotlib.rcParams['axes.linewidth'] = 1.2\n",
    "\n",
    "# def boxplot_ce(points, weights):\n",
    "#     plt.rc('text', usetex=True)\n",
    "#     plt.rcParams.update({\n",
    "#         \"text.usetex\": True,\n",
    "#         \"font.family\": \"serif\",\n",
    "#         \"font.serif\": [\"Times\"],\n",
    "#     })\n",
    "    \n",
    "#     assert len(points) == len(weights)\n",
    "    \n",
    "#     df = pd.DataFrame({\n",
    "#         'data': np.concatenate((points, weights)),\n",
    "#         'key' : np.concatenate((['means']*len(points), ['weights']*len(weights)))})\n",
    "\n",
    "#     plt.figure(figsize=(1.5,2))\n",
    "#     sns.violinplot(x='key', y='data', data=df) #color=\"0.15\")\n",
    "#     plt.xlabel('')\n",
    "#     plt.ylabel('')\n",
    "#     plt.ylim(-0.2, 0.3)    \n",
    "    \n",
    "# def boxplot_sc(points, title=None, outfile=None):    \n",
    "#     plt.rc('text', usetex=True)\n",
    "#     plt.rcParams.update({\n",
    "#         \"text.usetex\": True,\n",
    "#         \"font.family\": \"serif\",\n",
    "#         \"font.serif\": [\"Times\"],\n",
    "#     })\n",
    "    \n",
    "#     df = pd.DataFrame({\n",
    "#         'data': points,\n",
    "#         'key' : np.array(['means']*len(points)).reshape(-1)})\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(1,2))\n",
    "#     ax.axes.xaxis.set_visible(False)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "#     ax.tick_params(axis='both', which='minor', labelsize=12)\n",
    "    \n",
    "#     sns.violinplot(x='key', y='data', data=df)\n",
    "#     plt.ylim(0.45, 0.75)\n",
    "#     plt.xlabel('')\n",
    "#     plt.ylabel('')\n",
    "#     #plt.axhline(y=-1/9.0, xmin=0, xmax=1, color='tab:green')\n",
    "    \n",
    "#     if title is not None: plt.title(title, fontsize=12)\n",
    "#     if outfile is not None:\n",
    "#         plt.savefig(outfile, bbox_inches='tight', pad_inches=0.05)\n",
    "    \n",
    "\n",
    "# def boxplot_class_collapse(data, title=None, zoom=False, outfile=None):\n",
    "#     plt.rc('text', usetex=True)\n",
    "#     plt.rcParams.update({\n",
    "#         \"text.usetex\": True,\n",
    "#         \"font.family\": \"serif\",\n",
    "#         \"font.serif\": [\"Times\"],\n",
    "#     })\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(1.5,2))\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "#     ax.tick_params(axis='both', which='minor', labelsize=12)\n",
    "#     sns.violinplot(np.array(data).reshape(-1),orient='v',color='tab:red')\n",
    "#     plt.ylabel('',fontsize=12)\n",
    "#     if title is not None:\n",
    "#         plt.title(title, fontsize=12)\n",
    "#     plt.ylim(0,4)\n",
    "    \n",
    "#     if zoom:\n",
    "#         axins = ax.inset_axes([0.4, 0.1, 0.4, 1.0])\n",
    "#         sns.violinplot(np.array(data).reshape(-1),orient='v',color='tab:red', ax=axins)\n",
    "#         axins.set_xlim(-0.5, 0.5)\n",
    "#         axins.set_ylim(0, 0.1)\n",
    "#         ax.indicate_inset_zoom(axins)\n",
    "\n",
    "#     if outfile is not None:\n",
    "#         plt.savefig(outfile, bbox_inches='tight', pad_inches=0.05)\n",
    "        \n",
    "# boxplot_sc(P_sup_CAD, title=r'\\bf{SC}',         outfile='/tmp/exp_fig/SUP_cad.pdf')\n",
    "# boxplot_sc(P_cev_CAD, title=r'\\bf{CE-Vanilla}', outfile='/tmp/exp_fig/CEV_cad.pdf')\n",
    "# boxplot_sc(P_cef_CAD, title=r'\\bf{CE (Fix W)}',  outfile='/tmp/exp_fig/CEF_cad.pdf')\n",
    "\n",
    "# boxplot_class_collapse(P_sup_CC, r'\\bf{SC}', zoom=True,  outfile='/tmp/exp_fig/SC_collapse.pdf')\n",
    "# boxplot_class_collapse(P_cev_CC, r'\\bf{CEV}', zoom=False, outfile='/tmp/exp_fig/CEV_collapse.pdf')\n",
    "# boxplot_class_collapse(P_cef_CC, r'\\bf{CEF}', zoom=False, outfile='/tmp/exp_fig/CEF_collapse.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_norms = {}\n",
    "for k, r in named_results.items():\n",
    "    print(k)\n",
    "    weight_norms[k] = compute_linear_weights_norm(r.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_norms = {}\n",
    "for k, r in named_results.items(): \n",
    "    print(k)\n",
    "    latent_norms[k] = compute_latent_norms(r.path, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_innerprod_with_weight = {}\n",
    "for k, r in named_results.items(): \n",
    "    print(k)\n",
    "    latent_innerprod_with_weight[k] = compute_latent_innerprod_with_weight(r.path, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_geometry = dict()\n",
    "for k, r in named_results.items(): \n",
    "    print(k)\n",
    "    latent_geometry[k] = compute_latent_innerproducts_norm(r.path, train=True, sub_sample=10000, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in named_results:\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(4*5, 5))\n",
    "    fig.suptitle(k)\n",
    "    \n",
    "    ln, Y = latent_norms[k]\n",
    "    Y = torch.tensor(Y)\n",
    "    labels = sorted(set(Y.tolist()))\n",
    "    \n",
    "    axes[0].violinplot([ln[Y == y].numpy() for y in labels])\n",
    "    axes[0].set_title('norm distributions')\n",
    "    \n",
    "    wn = weight_norms[k]\n",
    "    axes[0].plot(list(range(1, len(labels)+1)), wn.numpy(), '.', label='norms of weights')\n",
    "    \n",
    "    prod, YY, norm = latent_geometry[k]\n",
    "    tmp = {}\n",
    "    for y_1 in range(len(labels)):\n",
    "        for y_2 in range(y_1, len(labels)):\n",
    "            tmp[y_1, y_2] = prod[(YY[:, 0] == y_1) & (YY[:, 1] == y_2)]\n",
    "            \n",
    "    mat_mean = torch.zeros((len(labels), len(labels)))\n",
    "    mat_std = torch.zeros((len(labels), len(labels)))\n",
    "    \n",
    "    axes[1].set_title('inner products mean')\n",
    "    for (y_1, y_2), prods in tmp.items():\n",
    "        mean = prods.mean().item()\n",
    "        mat_mean[y_1, y_2] = mean\n",
    "        mat_mean[y_2, y_1] = mean\n",
    "        \n",
    "    sns.heatmap(mat_mean, ax=axes[1])\n",
    "    \n",
    "    axes[2].set_title('innner products std')\n",
    "    for (y_1, y_2), prods in tmp.items():\n",
    "        std = prods.std().item()\n",
    "        mat_mean[y_1, y_2] = std\n",
    "        mat_mean[y_2, y_1] = std\n",
    "        \n",
    "    sns.heatmap(mat_mean, ax=axes[2])\n",
    "    \n",
    "    if not 'supcon' in k:\n",
    "    \n",
    "        axes[3].set_title('inner products to correct weight')\n",
    "        inprods, Y = latent_innerprod_with_weight[k]\n",
    "\n",
    "        Y = torch.tensor(Y).long()\n",
    "        I = torch.zeros_like(inprods, dtype=torch.bool)\n",
    "        I.scatter_(1, Y.unsqueeze(1), 1)\n",
    "\n",
    "        inprods_true = inprods[I]\n",
    "        inprods_true = [inprods_true[Y == y] for y in range(len(labels))]\n",
    "        axes[3].violinplot(inprods_true)\n",
    "\n",
    "        inprods_false = inprods[~I].view(-1, len(labels) - 1)\n",
    "        inprods_false = [inprods_false[Y == y].view(-1) for y in range(len(labels))]\n",
    "        axes[3].violinplot(inprods_false)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
