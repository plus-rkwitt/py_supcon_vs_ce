{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import qgrid\n",
    "import torch\n",
    "import collections\n",
    "import functools\n",
    "\n",
    "from pytorch_utils.logging import LoggerReader\n",
    "from pytorch_utils.collection_utils import keychain_value_iter\n",
    "from collections import defaultdict, OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from millify import millify\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from nb_common import load_results, args_df_from_results, progress\n",
    "\n",
    "DEVICE = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = Path('/scratch2/chofer/toporeg_sandbox/'\n",
    "\n",
    "# root = Path('/tmp/tmp_results')\n",
    "# root = Path('/tmp/testing')\n",
    "# root = Path('/tmp/debug')\n",
    "#root = Path('/tmp/grid_1')\n",
    "\n",
    "\n",
    "# root = Path('/home/pma/chofer/repositories/py_supcon_vs_ce/results')\n",
    "#root = Path('/home/pma/chofer/repositories/py_supcon_vs_ce/results_random_label/')\n",
    "# root = Path('/home/pma/chofer/repositories/py_supcon_vs_ce/results_noisy_label/')\n",
    "#root = Path('/home/pma/chofer/repositories/py_supcon_vs_ce/results_xmas_noisy_label/')\n",
    "root = Path('/home/pma/chofer/repositories/py_supcon_vs_ce/results_xmas_performance/')\n",
    "#root = Path('/tmp/test/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args_white_list = {\n",
    "#     'num_runs',\n",
    "#     'num_samples',\n",
    "#     'num_batches',\n",
    "#     'batch_size',\n",
    "#     'tag', \n",
    "#     'eval_interval',\n",
    "#     'model', \n",
    "#     'lr_init',\n",
    "#     'weight_decay',\n",
    "#     'ds_train',\n",
    "#     'ds_test' ,\n",
    "#     'momentum',\n",
    "#     'augment',\n",
    "#     'losses',\n",
    "#     'w_losses',\n",
    "#     'label_noise_fraction'\n",
    "# }\n",
    "\n",
    "args_white_list = {\n",
    "    'num_batches',\n",
    "    'batch_size',\n",
    "    'tag', \n",
    "    'weight_decay',\n",
    "    'ds_train',\n",
    "    'ds_test' ,\n",
    "    'augment',\n",
    "    'scheduler'\n",
    "}\n",
    "\n",
    "args_simple = {\n",
    "    'model_comp': lambda a: a['model'][1]['compactification_cfg'][0], \n",
    "    'model_lin': lambda a: a['model'][1]['linear_cfg'][0], \n",
    "    'loss': lambda a: a['losses'][0][0],\n",
    "}\n",
    "\n",
    "# tag='spectral_norm'\n",
    "tag = None\n",
    "\n",
    "\n",
    "args_df_from_results = functools.partial(args_df_from_results, args_white_list=args_white_list, args_simple=args_simple)\n",
    "\n",
    "\n",
    "\n",
    "def progress_from_results():\n",
    "    RESULTS = load_results(root, tag=tag)\n",
    "    \n",
    "    tmp = defaultdict(list)\n",
    "    \n",
    "    for i, r in enumerate(RESULTS):\n",
    "        \n",
    "        p = progress(r)\n",
    "        \n",
    "        if isinstance(p, str):\n",
    "            tmp['Idx'].append(i)\n",
    "            tmp['progress'].append(p)\n",
    "            tmp['path'].append(r.path)\n",
    "            \n",
    "    return pd.DataFrame(tmp)\n",
    "    \n",
    "\n",
    "def df_from_results():\n",
    "    RESULTS = load_results(root, tag=tag)\n",
    "    A = args_df_from_results(RESULTS)\n",
    "    progress\n",
    "    tmp = []\n",
    "    for i, r in enumerate(RESULTS):\n",
    "        df = {}\n",
    "        for k in [\n",
    "            'linear_train',\n",
    "            'linear_test',\n",
    "            'retrained_linear_train',\n",
    "            'retrained_linear_test',\n",
    "            'explicit_linear_train', \n",
    "            'explicit_linear_test'        \n",
    "        ]:\n",
    "            try:\n",
    "                df[k] = np.mean([run[k][-1] for run in r])\n",
    "                \n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "        tmp.append(pd.DataFrame(df, index=[i]))\n",
    "    \n",
    "    B = pd.concat(tmp, sort=False)\n",
    "    return A.join(B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_losses(idx,from_batch_i=0):\n",
    "    RESULTS = load_results(root)\n",
    "    plt.figure() \n",
    "    \n",
    "    r = RESULTS[idx][0] \n",
    "    \n",
    "    for k, v in r.items():\n",
    "        \n",
    "        if 'batch_' in k and k not in ['batch_cls_loss', 'batch_i']:\n",
    "            Y = r[k][from_batch_i:]\n",
    "            X = list(range(len(Y)))\n",
    "            plt.plot(X, Y, label=k.split('batch_')[1], alpha=0.5)\n",
    "            \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "def plt_curves(idx, keys):\n",
    "    if isinstance(keys, str):\n",
    "        keys = [keys]\n",
    "    RESULTS = load_results(root)\n",
    "    plt.figure() \n",
    "    \n",
    "    r = RESULTS[idx][0] \n",
    "    \n",
    "    for k in keys:\n",
    "        plt.plot(r[k], label=k)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "def plt_loss_from_multiple_exp(idxs, loss_name, from_batch_i=0, to_batch_i=0, labeler=None, run_i=0):\n",
    "    RESULTS = load_results(root)\n",
    "    plt.figure() \n",
    "    \n",
    "    for idx in idxs:\n",
    "        \n",
    "        r = RESULTS[idx]\n",
    "        label = 'Idx_{}'.format(idx) if labeler is None else str(labeler(r))\n",
    "        plt.plot(r[run_i][loss_name][from_batch_i:to_batch_i], label=label, linewidth=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    \n",
    "def args_diff(idx_1, idx_2):\n",
    "    R = load_results(root)\n",
    "    a_1 = R[idx_1].experiment_args\n",
    "    a_2 = R[idx_2].experiment_args\n",
    "    \n",
    "    for (k_1, v_1), (k_2, v_2) in zip(keychain_value_iter(a_1), keychain_value_iter(a_2)):\n",
    "        assert k_1 == k_2 \n",
    "        if v_1 != v_2:\n",
    "            print(k_1, ':')            \n",
    "            print('\\t', idx_1, ':' , v_1)\n",
    "            print('\\t', idx_2, ':' , v_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_from_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a598397c1604299a4be2217811a7e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defauâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid_widget = qgrid.show_grid(df_from_results(), show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model'] :\n",
      "\t 8 : ['ResNet18', {'compactification_cfg': ['none', {}], 'linear_cfg': ['Linear', {'bias': False}], 'batch_norm': True, 'latent_dim': None}]\n",
      "\t 0 : ['ResNet18', {'compactification_cfg': ['sphere_l2', {}], 'latent_dim': None, 'linear_cfg': ['Linear', {'bias': False}], 'batch_norm': True}]\n",
      "['losses'] :\n",
      "\t 8 : [['CrossEntropy', {'reduction': 'mean'}]]\n",
      "\t 0 : [['SupConLoss', {'temperature': 0.1}]]\n",
      "['losses_track_only'] :\n",
      "\t 8 : [['SupConLoss', {'temperature': 0.1, 'project_input_to_sphere': True}]]\n",
      "\t 0 : []\n"
     ]
    }
   ],
   "source": [
    "      \n",
    "args_diff(8, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = load_results(root)\n",
    "from nb_common import *\n",
    "\n",
    "def get_cls_weights(path, run_i=0):\n",
    "    ctx = load_experiment_context(path, run_i=run_i)    \n",
    "    return ctx['model'].cls.weight.data\n",
    "\n",
    "print(np.array(R[26][0]['batch_CrossEntropy'][-1000:]).mean())\n",
    "weights = get_cls_weights(load_results(root)[26].path)\n",
    "print(weights.norm(dim=1).mean(), weights.norm(dim=1).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.log(1+(10.0-1)*np.exp(-1*weights.norm(dim=1).mean().item()*10.0/(10.0-1))))\n",
    "plt.figure(figsize=(6,1))\n",
    "plt.plot(weights.mean(dim=0).view(-1))\n",
    "print(weights.mean(dim=0).norm(p=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_root_dir': '/home/pma/chofer/repositories/py_supcon_vs_ce/results_xmas_performance',\n",
       " 'num_batches': 100000,\n",
       " 'tag': 'performance',\n",
       " 'eval_interval': 100000,\n",
       " 'num_runs': 1,\n",
       " 'num_samples': None,\n",
       " 'model': ['ResNet18',\n",
       "  {'compactification_cfg': ['sphere_l2', {}],\n",
       "   'latent_dim': None,\n",
       "   'linear_cfg': ['Linear', {'bias': False}],\n",
       "   'batch_norm': True}],\n",
       " 'lr_init': 0.1,\n",
       " 'weight_decay': 0.0001,\n",
       " 'ds_train': 'cifar100_train',\n",
       " 'ds_test': 'cifar100_test',\n",
       " 'momentum': 0.9,\n",
       " 'augment': 'none',\n",
       " 'batch_size': 256,\n",
       " 'losses': [['SupConLoss', {'temperature': 0.1}]],\n",
       " 'losses_track_only': [],\n",
       " 'w_losses': None,\n",
       " 'evaluation_policies': ['linear', 'retrained_linear', 'explicit_linear'],\n",
       " 'scheduler': 'exponential',\n",
       " 'experiment_type': 'core.experiment.Experiment'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = load_results(root)\n",
    "\n",
    "R[4].experiment_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 256\n",
      "CE (Fixed)      | 73.88\n",
      "5 512\n",
      "CE (Fixed)      | 73.41\n",
      "5 256\n",
      "CE (Vanilla)    | 73.27\n",
      "5 512\n",
      "CE (Vanilla)    | 73.92\n",
      "5 256\n",
      "CE (Spherical)  | 75.59\n",
      "5 512\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'retrained_linear_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1942fbd8e76c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m                     r[0]['retrained_linear_test'][0]))\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mprint_performance_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cifar100_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-1942fbd8e76c>\u001b[0m in \u001b[0;36mprint_performance_table\u001b[0;34m(root, ds, aug)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 print('{:15s} | {:.2f}'.format(\n\u001b[1;32m     74\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     r[0]['retrained_linear_test'][0]))\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mprint_performance_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cifar100_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'standard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/pytorch_utils/pytorch_utils/logging.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__call__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'retrained_linear_test'"
     ]
    }
   ],
   "source": [
    "def print_performance_table(root, ds='cifar10_train', aug='none'):\n",
    "    R = load_results(root)\n",
    "    match = {'CE (Fixed)':\n",
    "                {\n",
    "                    'ds_train' : ds,\n",
    "                    'augment'  : aug,\n",
    "                    'scheduler': 'exponential',\n",
    "                    'losses'   : [['CrossEntropy', {'reduction': 'mean'}]],\n",
    "                    'model': ['ResNet18',\n",
    "                        {\n",
    "                            'compactification_cfg': ['none', {}],\n",
    "                            'linear_cfg': ['FixedSphericalSimplexLinear', {}],\n",
    "                            'batch_norm': True,\n",
    "                            'latent_dim': None\n",
    "                        }]\n",
    "                },\n",
    "             'CE (Vanilla)':\n",
    "                {\n",
    "                    'ds_train' : ds,\n",
    "                    'augment'  : aug,\n",
    "                    'scheduler': 'exponential',\n",
    "                    'losses'   : [['CrossEntropy', {'reduction': 'mean'}]],\n",
    "                    'model': ['ResNet18',\n",
    "                        {\n",
    "                           'compactification_cfg': ['none', {}],\n",
    "                           'linear_cfg': ['Linear', {'bias': False}],\n",
    "                           'batch_norm': True,\n",
    "                           'latent_dim': None\n",
    "                        }] \n",
    "                },\n",
    "             'CE (Spherical)':\n",
    "                {\n",
    "                    'ds_train' : ds,\n",
    "                    'augment'  : aug,\n",
    "                    'scheduler': 'exponential',\n",
    "                    'losses'   : [['CrossEntropy', {'reduction': 'mean'}]],\n",
    "                    'model': ['ResNet18',\n",
    "                        {\n",
    "                           'compactification_cfg': ['sphere_l2', {}],\n",
    "                           'linear_cfg': ['Linear', {'bias': False}],\n",
    "                           'batch_norm': True,\n",
    "                           'latent_dim': None\n",
    "                        }] \n",
    "                },\n",
    "             'SupCon':\n",
    "                {\n",
    "                    'ds_train' : ds,\n",
    "                    'augment'  : aug,\n",
    "                    'scheduler': 'exponential',\n",
    "                    'losses': [['SupConLoss', {'temperature': 0.1}]],\n",
    "                    'model': ['ResNet18',\n",
    "                        {\n",
    "                           'compactification_cfg': ['sphere_l2', {}],\n",
    "                           'linear_cfg': ['Linear', {'bias': False}],\n",
    "                           'batch_norm': True,\n",
    "                           'latent_dim': None\n",
    "                        }] \n",
    "                }\n",
    "            }\n",
    "\n",
    "    n_match = len(match) \n",
    "\n",
    "    for method, m in match.items():\n",
    "        n_match = len(m)\n",
    "        for r in R:\n",
    "            found = 0\n",
    "            for k,v in m.items():\n",
    "                if r.experiment_args[k] == v:\n",
    "                    found += 1 \n",
    "\n",
    "            if found == n_match:\n",
    "                print(found, r.experiment_args['batch_size'])\n",
    "                print('{:15s} | {:.2f}'.format(\n",
    "                    method,\n",
    "                    r[0]['retrained_linear_test'][0]))\n",
    "            \n",
    "print_performance_table(root, ds='cifar100_train', aug='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plt_label_noise(tag=None):\n",
    "    tag = tag\n",
    "    R = load_results(root, tag=tag)\n",
    "#     assert len(set((r.experiment_args['num_batches'] for r in R))) == 1\n",
    "#     assert len(set((r.experiment_args['eval_interval'] for r in R))) == 1\n",
    "    \n",
    "    eval_int = R[0].experiment_args['eval_interval']\n",
    "    \n",
    "    key = lambda x: x.experiment_args['label_noise_fraction']\n",
    "\n",
    "    l_ce = sorted([r for r in R if r.experiment_args['losses'][0][0] == 'CrossEntropy'], key=key)\n",
    "    l_supcon = sorted([r for r in R if r.experiment_args['losses'][0][0] == 'SupConLoss'], key=key)\n",
    "\n",
    "    for ce, supcon in zip(l_ce, l_supcon):\n",
    "        plt.figure()\n",
    "        #assert key(ce) == key(supcon)\n",
    "        plt.title(\"label_fraction  \" +  str(key(ce)))\n",
    "        \n",
    "        \n",
    "        acc = ce[0]['retrained_linear_train']\n",
    "        X = [i*eval_int for i in range(len(acc))]\n",
    "        plt.plot(X, acc, label='ce')\n",
    "        \n",
    "        acc = supcon[0]['retrained_linear_train']\n",
    "        X = [i*eval_int for i in range(len(acc))]\n",
    "        plt.plot(X, acc, label='supcon last={:.2f}'.format(acc[-1]))\n",
    "        plt.gca().axhline(acc[-1], linestyle='--', color='gray')\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.ylim((0, 100))\n",
    "        \n",
    "plt_label_noise(tag='no_momentum')\n",
    "# for r in sorted(tmp[k], key=lambda x: x.experiment_args[''])\n",
    "\n",
    "# plt.plot(load_results(root, tag=tag)[idx][0]['retrained_linear_train'])\n",
    "# plt.grid()\n",
    "# plt.figure()\n",
    "# plt.plot(np.array(load_results(root, tag=tag)[idx][0]['retrained_linear_loss']).T);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_csv(idxs, root, loss_name):\n",
    "    res = load_results(root)\n",
    "    D = {}\n",
    "    for i in idxs:\n",
    "        col_str = '{}'.format(res[i].experiment_args['label_noise_fraction'])\n",
    "        D[col_str] = res[i][0][loss_name]\n",
    "    \n",
    "    return D\n",
    "        \n",
    "to_csv = pd.DataFrame(data=export_csv([21,23,24,32],root,'batch_SupConLoss'))\n",
    "to_csv.to_csv('/tmp/res.csv', index_label='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_curves(-1, [\n",
    "# #     'r_linear', \n",
    "# #     'tracked_ce_loss_spherical', \n",
    "#     'retrained_linear_loss'\n",
    "# #     'batch_CrossEntropy'\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label_noise_fraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-416b665348c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plt_loss_from_multiple_exp([59], 'batch_CrossEntropy', \n\u001b[1;32m      2\u001b[0m                            \u001b[0mlabeler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_noise_fraction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                            from_batch_i=50, to_batch_i=100000)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-7016c157a8e7>\u001b[0m in \u001b[0;36mplt_loss_from_multiple_exp\u001b[0;34m(idxs, loss_name, from_batch_i, to_batch_i, labeler, run_i)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRESULTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Idx_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabeler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrom_batch_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mto_batch_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-416b665348c1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m plt_loss_from_multiple_exp([59], 'batch_CrossEntropy', \n\u001b[0;32m----> 2\u001b[0;31m                            \u001b[0mlabeler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_noise_fraction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                            from_batch_i=50, to_batch_i=100000)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_noise_fraction'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_loss_from_multiple_exp([59], 'batch_CrossEntropy', \n",
    "                           labeler=lambda x: x.experiment_args['label_noise_fraction'], \n",
    "                           from_batch_i=50, to_batch_i=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt_loss_from_multiple_exp([21], #[14,16,18,20],#[0,6,12,20], #[3,5,7,9,11,13,15,17,19,21], #[0,1,2,6,8,10,12,14],#, \n",
    "                           'batch_SupConLoss', \n",
    "                           labeler=lambda x: x.experiment_args['label_noise_fraction'], \n",
    "                           from_batch_i=0,\n",
    "                           to_batch_i=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt_loss_from_multiple_exp([1], 'batch_CrossEntropy', labeler=lambda x: x.experiment_args['num_samples'], from_batch_i=100)\n",
    "#plt_loss_from_multiple_exp([11, 12, 13, 14, 15], 'batch_SupConLoss', labeler=lambda x: x.experiment_args['num_samples'], from_batch_i=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_batch_size_degeneration():\n",
    "    R = load_results(root)\n",
    "    R = [r for r in R if r.experiment_args['tag'] == 'small_batches_degeneration']\n",
    "    \n",
    "    eval_policies = ['retrained_linear_train', 'retrained_linear_test', 'explicit_linear_train', 'explicit_linear_test']\n",
    "    \n",
    "    for aug_policy in ['none', 'supcon']:\n",
    "        \n",
    "        RR = [r for r in R if r.experiment_args['augment'] == aug_policy]\n",
    "        RR = sorted(RR, key=lambda x: x.experiment_args['batch_size'])\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Augmentation policy: ' + aug_policy)\n",
    "        \n",
    "        X = [r.experiment_args['batch_size'] for r in RR]\n",
    "        \n",
    "        for eval_p in eval_policies:\n",
    "            Y = [r[0][eval_p][-1] for r in RR]\n",
    "            \n",
    "            plt.plot(X, Y, label=eval_p)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.xlabel('batch size')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.grid()\n",
    "        \n",
    "plt_batch_size_degeneration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = load_results(root)[-1]\n",
    "print(r.experiment_args['losses'])\n",
    "r[0]['retrained_linear_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_norms():\n",
    "    R = load_results(root, tag='norms_of_w')\n",
    "#     R = load_results(root)[-1:]\n",
    "    \n",
    "    for r in R:\n",
    "        \n",
    "        title = ''\n",
    "        \n",
    "        title += r.experiment_args['model'][1]['compactification']\n",
    "        title += ', '\n",
    "        title += r.experiment_args['experiment_type']\n",
    "        \n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(title)\n",
    "         \n",
    "        X = np.array(r[0]['norm_w']).T\n",
    "        \n",
    "        for x in X: \n",
    "            plt.plot(x)\n",
    "        \n",
    "        \n",
    "    \n",
    "plt_norms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_trained_vanilla_ce_tracked_spherical_ce():\n",
    "    R = load_results(root, tag='optimize_vanilla_ce_track_spherical_ce')\n",
    "    print(len(R))\n",
    "    \n",
    "    \n",
    "    for r in R:\n",
    "        print(r.experiment_args)\n",
    "        plt.figure()\n",
    "        for k in ['batch_CrossEntropy', 'tracked_ce_loss_spherical']:\n",
    "            plt.plot(r[0][k], label=k)\n",
    "    plt.legend()\n",
    "\n",
    "plt_trained_vanilla_ce_tracked_spherical_ce()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
